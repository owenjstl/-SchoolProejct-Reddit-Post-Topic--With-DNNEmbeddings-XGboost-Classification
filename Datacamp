##

### 1 Read the data

# Import pandas
import pandas as pd
data = pd.read_csv("", header = None)
# Inspect data
.head()

### 2 Inspecting the data

# Summary statistics
.describe()
# DataFrame information
.info()

### Splitting the dataset into train and test sets
# Import train_test_split
from sklearn.model_selection import train_test_split
#Drop the features
.drop([ ], axis = 1)
# Split into train and test sets
train_test_split(data, test_size=0.33, random_state=42)

# Handling the missing values (part i) 
Replace xxx with NaN : replace(xxx, np.NaN)
Mean imputation : .fillna(data.mean(), inplace=True)
Count the number of NaNs in the data set : data.isnull().sum())
more frequent value as inputation:
for col in data.columns:
    # Check if the column is of object type
    if data[col].dtypes == 'object':
        # Impute with the most frequent value
        data = data.fillna(data[col].value_counts().index[0])
Check the number of NaNs:
print(data.isnull().sum())

### Data Preprocessing
1 Convert the non-numeric data into numeric.
2 Scale the feature values to a uniform range.

data = pd.get_dummies(data)
# Reindex the columns of the test set aligning with the train set
data_test = data_test.reindex(columns=data_train.columns, fill_value=0)

Import MinMaxScaler
from sklearn.preprocessing import MinMaxScaler

# Segregate features and labels into separate variables
X_train, y_train = data_train.iloc[:, :-1].values, data_train.iloc[:, [-1]].values

#Grid Searching and making the model perform better

# Import GridSearchCV
from sklearn.model_selection import GridSearchCV
# Define the grid of values for tol and max_iter
tol = [0.01, 0.001 ,0.0001]
max_iter = [100, 150, 200]

# Create a dictionary where tol and max_iter are keys and the lists of their values are the corresponding values
param_grid = dict(tol=tol, max_iter=max_iter)

 Instantiate GridSearchCV with the required parameters
grid_model = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5)

# Fit grid_model to the data
grid_model_result = grid_model.fit(rescaledX_train, y_train)

# Summarize results
best_score, best_params = grid_model_result.best_score_, grid_model_result.best_params_
print("Best: %f using %s" % (best_score, best_params))

# Extract the best model and evaluate it on the test set
best_model = grid_model_result.best_estimator_
print("Accuracy of logistic regression classifier: ", best_model.score(rescaledX_test,y_test))

